# Business Requirements Document (BRD)

**1. Project Title:** SonarQube Metrics & Trends Dashboard

**2. Date:** 5/22/2025

**3. Version:** 1.0

**4. Related Project:** Containerized CI Pipeline: Gitea, Jenkins & SonarQube for Automated Python Code Scans (BRD v1.1)

**5. Project Overview & Purpose:**
This project extends the capabilities of the "Containerized CI Pipeline" (BRD v1.0) by adding a dedicated analytics and visualization layer. It involves creating a Streamlit dashboard to display key SonarQube metrics, trends over time, and project comparisons. Data will be extracted from the SonarQube instance (established in BRD v1.1) via an Apache Airflow ETL process and stored in a PostgreSQL database for efficient querying and historical analysis. The entire new stack (Streamlit, Airflow, PostgreSQL) will also be containerized and integrated into the existing Docker Compose setup.

**6. Business Objectives & Goals:**

* **Enhanced Code Quality Insight:** Provide developers and tech leads with an easy-to-understand visual dashboard of SonarQube metrics.
* **Track Progress Over Time:** Enable monitoring of code quality, security, reliability, and maintainability trends for scanned projects.
* **Facilitate Project Comparison:** Allow for benchmarking of different projects against each other based on key metrics.
* **Data-Driven Decision Making:** Offer tangible data to support discussions and decisions related to code improvement efforts.
* **Centralized Metrics View:** Consolidate important SonarQube data into a single, accessible dashboard.
* **Automated Data Collection:** Ensure metrics are regularly and automatically updated in the dashboard.

**7. Scope:**

**7.1. In Scope:**

* **Dashboard Application (Streamlit):**
  * Development of a Streamlit web application to serve as the dashboard.
  * **Section 1: KPI Cards:** Display main SonarQube metrics (Bugs, Vulnerabilities, Code Smells, Coverage, Duplications, Security Hotspots) with trend indicators (up, down, still based on comparison to previous equivalent period, +/- 2% threshold for "still").
  * **Section 2: Trends Over Time:** Visualizations (e.g., line charts) showing the historical trend of each selected KPI. Default view: Last week. Granularity: Dynamic (e.g., daily for week view).
  * **Section 3: Project Comparison:** Horizontal bar graphs comparing all (or selected) SonarQube projects for each KPI. Default: All projects.
  * **Section 4: Data Table:** Display raw, filtered data for selected KPIs, projects, and date ranges. Option to export this table to CSV.
  * **Filtering Capabilities:**
    * Filter by Metric Category: Security (Vulnerabilities, Security Hotspots), Reliability (Bugs), Maintainability (Code Smells, Duplications), Coverage (Coverage).
    * Filter by Date Range: Predefined (This Week, This Month, This Quarter, This Year, Last 30 days) and a custom date range picker.
    * Metric-Specific Filters:
      * Bugs: Severity (Blocker, Critical, Major, Minor), Status (Open, Confirmed, Reopened).
      * Vulnerabilities: Severity (Critical, High, Medium, Low), Status (Open, Confirmed, Reopened).
      * Code Smells: Severity (Blocker, Critical, Major, Minor).
      * Security Hotspots: Severity (High, Medium, Low), Status (To Review, Reviewed, Acknowledged, Fixed).
* **ETL Process (Apache Airflow):**
  * Creation of an Airflow DAG to extract data from the SonarQube API.
  * Transformation of fetched data into a suitable format for storage.
  * Loading data into a PostgreSQL database.
  * Scheduled to run nightly.
  * Initial historical data pull for the last 3 months.
  * Ability to query SonarQube for a list of all available projects to monitor.
  * Mechanism to carry forward the last known metric value if a new scan is not available for a particular day.
  * Error handling with retries (3 times, exponential backoff).
* **Data Persistence (PostgreSQL):**
  * Setup of a PostgreSQL database to store historical SonarQube metrics.
  * Definition of a database schema to store project information and their time-series metrics.
  * Data retention policy: 2 years.
* **Containerization & Integration (Docker Compose):**
  * Containerization of the Streamlit application.
  * Containerization of Apache Airflow (scheduler, webserver, worker as appropriate).
  * Containerization of PostgreSQL.
  * Integration of these new services into the existing `docker-compose.yml` file from BRD v1.1.
* **Documentation:**
  * Instructions for accessing the Streamlit dashboard.
  * Overview of Airflow DAGs and how to monitor them (briefly).
  * Notes on PostgreSQL data schema (high-level).

**7.2. Out of Scope:**

* User authentication/authorization for the Streamlit dashboard (for this version).
* Writing data back to SonarQube from the dashboard.
* Real-time (sub-minute) dashboard updates; updates are based on ETL frequency.
* Automated alerting based on metric thresholds or ETL failures (beyond Airflow's native logging/UI).
* Predictive analytics or forecasting.
* Customization of dashboard appearance beyond Streamlit's default capabilities or minor theming.
* Direct modification of SonarQube configurations via this dashboard.
* Advanced performance tuning for extremely large SonarQube instances (hundreds of projects with very long histories) beyond reasonable defaults.

**8. Functional Requirements (FR):**

* **FR-DASH1:** The system MUST provide a Streamlit dashboard accessible via a web browser on `localhost` (on a distinct port).
* **FR-DASH2 (KPI Cards):** The dashboard MUST display KPI cards for Bugs, Vulnerabilities, Code Smells, Coverage, Duplications, and Security Hotspots, each showing the current value and a trend indicator (up, down, or still).
* **FR-DASH3 (Trend Logic):** The trend indicator for KPI cards MUST be determined by comparing the current value to the value from the start of the previous equivalent period (e.g., 'Last 30 days' compares to 30 days ago), with "still" if the change is within +/- 2%.
* **FR-DASH4 (Trend Graphs):** The dashboard MUST display historical trend graphs for each selected KPI, with a default view of "Last week" and dynamic data point granularity.
* **FR-DASH5 (Project Comparison):** The dashboard MUST allow comparison of selected SonarQube projects (defaulting to all) for each KPI, displayed as a horizontal bar graph.
* **FR-DASH6 (Data Table):** The dashboard MUST display a filterable data table showing the raw metric values for selected projects, KPIs, and date ranges.
* **FR-DASH7 (CSV Export):** Users MUST be able to export the displayed data table to a CSV file.
* **FR-DASH8 (Category Filter):** The dashboard MUST allow filtering of displayed metrics by categories: Security, Reliability, Maintainability, and Coverage.
* **FR-DASH9 (Date Filter):** The dashboard MUST provide predefined date range filters (This Week, This Month, This Quarter, This Year, Last 30 days) AND a custom date range picker.
* **FR-DASH10 (Metric-Specific Filters):** The dashboard MUST provide specific sub-filters for:
  * Bugs: Severity, Status.
  * Vulnerabilities: Severity, Status.
  * Code Smells: Severity.
  * Security Hotspots: Severity, Status.
* **FR-ETL1 (Data Extraction):** An Apache Airflow DAG MUST extract metrics (Bugs, Vulnerabilities, Code Smells, Coverage, Duplications, Security Hotspots, and their relevant attributes like severity/status) from the SonarQube API for all configured projects.
* **FR-ETL2 (Scheduling):** The Airflow DAG MUST be scheduled to run automatically on a nightly basis.
* **FR-ETL3 (Historical Load):** Upon its first successful run for a project, the ETL process MUST attempt to load historical data for the last 3 months from SonarQube.
* **FR-ETL4 (Dynamic Project Discovery):** Airflow MUST dynamically fetch the list of projects to monitor from the SonarQube API.
* **FR-ETL5 (Data Transformation):** The ETL process MUST transform extracted data into a structured format suitable for storage in PostgreSQL, including timestamps.
* **FR-ETL6 (Data Loading):** The ETL process MUST load the transformed data into the PostgreSQL database.
* **FR-ETL7 (Carry Forward Logic):** If SonarQube data for a specific day/project is unavailable, the ETL MUST carry forward the last known valid metric values, marking them appropriately.
* **FR-DB1 (Data Persistence):** SonarQube metrics data collected by Airflow MUST be persisted in a PostgreSQL database.
* **FR-DB2 (Data Retrieval):** The Streamlit application MUST retrieve data from the PostgreSQL database to populate the dashboard.
* **FR-INT1 (Docker Compose):** The Streamlit application, Apache Airflow, and PostgreSQL database MUST be defined as services within the project's `docker-compose.yml` file and be launchable with `docker-compose up`.

**9. Non-Functional Requirements (NFR):**

* **NFR1 (Performance - Dashboard Load):** The Streamlit dashboard initial load time SHOULD be less than 10 seconds.
* **NFR2 (Performance - Filter Application):** Applying filters and updating graphs on the dashboard SHOULD take less than 3 seconds for typical datasets.
* **NFR3 (Performance - ETL Duration):** The nightly Airflow ETL DAG run (for an initial set of 5-10 projects, including 3 months history on first run) SHOULD complete within 30 minutes.
* **NFR4 (Reliability - ETL):** The Airflow ETL process MUST retry at least 3 times upon failure with exponential backoff. Errors MUST be logged in Airflow.
* **NFR5 (Reliability - Data):** The system should correctly implement the carry-forward logic for missing daily data points to ensure continuous trend lines.
* **NFR6 (Usability):** The Streamlit dashboard MUST be intuitive and easy for developers and tech leads to navigate and understand.
* **NFR7 (Maintainability):** Code for the Streamlit application and Airflow DAGs SHOULD be well-commented and organized. The PostgreSQL schema should be documented.
* **NFR8 (Scalability - Initial):** The system should handle metrics from at least 10-20 SonarQube projects with daily data points for 2 years without significant performance degradation.
* **NFR9 (Security):** The Airflow component will use the SonarQube token (configured as per BRD v1.1) securely. The dashboard itself will not implement additional authentication for this version and will be accessible on localhost.
* **NFR10 (Portability):** The entire extended stack (including new components) MUST run on any system with Docker Desktop and Docker Compose installed, complementing BRD v1.1.
* **NFR11 (Resource Usage):** The combined resource usage of the new components (Streamlit, Airflow, Postgres) SHOULD be reasonable for a typical developer machine running Docker Desktop.
* **NFR12 (Data Retention):** Data in the PostgreSQL database MUST be retained for 2 years, with older data potentially being archived or purged (mechanism TBD if explicitly needed beyond simple deletion).

**10. Data Requirements:**

* **10.1. Data Sources:**
  * Primary: SonarQube API (from the instance set up as per BRD v1.1). Specific endpoints for projects, measures/metrics, issues.
* **10.2. Data Storage:**
  * Technology: PostgreSQL (containerized).
  * Purpose: Store historical time-series data of SonarQube metrics and relevant project metadata.
* **10.3. ETL (Extract, Transform, Load):**
  * Orchestration Tool: Apache Airflow (containerized).
  * Extraction: Query SonarQube API for project lists and their metrics (Bugs, Vulnerabilities, Code Smells, Coverage, Duplications, Security Hotspots, including severities, statuses where applicable).
  * Transformation: Map API responses to database schema. Convert data types. Calculate trend indicators if done at ETL time (alternative: calculate in Streamlit on-the-fly). Handle missing data by carrying forward last known values.
  * Loading: Insert/update records in PostgreSQL tables.
  * Frequency: Nightly.
  * Historical Data: Pull data for the last 3 months on the first run for each project.
* **10.4. Conceptual Data Model (PostgreSQL - High Level):**
  * `sq_projects`: (project_id (PK), sonarqube_project_key, project_name, first_seen_at, last_analysis_date_from_sq)
  * `daily_project_metrics`: (metric_id (PK), project_id (FK), metric_date, bugs_total, bugs_blocker, bugs_critical, ..., vulnerabilities_total, vulnerabilities_critical, ..., codesmells_total, ..., coverage_percentage, duplicated_lines_density, security_hotspots_total, security_hotspots_high, ..., data_source_timestamp (when SQ data was pulled), is_carried_forward (boolean))
  * (Further tables for issue statuses/types if needed for granular filtering and not easily aggregated).
* **10.5. Data Retention:** Data in PostgreSQL to be retained for 2 years.

**11. Technical Requirements / High-Level Architecture:**

* **Dashboard Application:** Streamlit (Python).
* **ETL Orchestrator:** Apache Airflow (using official Docker images).
* **Database:** PostgreSQL (using official Docker image).
* **Containerization:** All new components (Streamlit App, Airflow, Postgres) will be defined as services in the existing `docker-compose.yml` from BRD v1.1.
* **Networking:** Services will communicate over the Docker Compose default network. Streamlit will be exposed on a `localhost` port. Airflow UI will be exposed on a `localhost` port. Postgres will typically only be accessible by other containers on the Docker network.
* **Workflow:**
    1. The CI pipeline (Gitea, Jenkins, SonarQube - from BRD v1.1) operates, and SonarQube is populated with analysis data.
    2. The Apache Airflow DAG runs on its nightly schedule.
        a.  Task 1: Query SonarQube API to get a list of all projects.
        b.  Task 2 (loops per project): Query SonarQube API for the required metrics for a given project for the relevant period (e.g., last day, or historical period for backfill).
        c.  Task 3: Transform the retrieved data (handle types, severities, statuses, carry-forward logic).
        d.  Task 4: Load the transformed data into the PostgreSQL `daily_project_metrics` and update `sq_projects` tables.
    3. A user accesses the Streamlit dashboard URL in their browser.
    4. The Streamlit application, on load or when filters change:
        a.  Queries the PostgreSQL database based on current filter selections.
        b.  Processes the data for display (e.g., aggregates for KPI cards, prepares data series for charts).
        c.  Renders the KPI cards, trend graphs, project comparison charts, and data table.

**12. Assumptions:**

* The Gitea, Jenkins, and SonarQube stack (as per BRD v1.1) is already set up and operational.
* The SonarQube instance has an accessible API, and the necessary API token is available to Airflow (e.g., via Docker environment variables or Airflow connections).
* The user's machine has sufficient resources (CPU, RAM, Disk) to run the additional containers (Streamlit, Airflow, Postgres) alongside the existing ones.
* The user can access `localhost` ports via a web browser for the Streamlit dashboard and Airflow UI.
* Basic familiarity with SonarQube metrics is assumed for users of the dashboard.

**13. Constraints:**

* Must use Streamlit for the dashboard, Apache Airflow for ETL, and PostgreSQL for the database.
* All new components MUST be containerized and integrated into the existing `docker-compose.yml` file.
* The dashboard is for visualization and data exploration; it will not modify data in SonarQube.
* The solution will rely on SonarQube's API capabilities for data extraction.

**14. Risks & Mitigation:**

* **Risk:** Complexity in developing robust Airflow DAGs for SonarQube API pagination, error handling, and data transformations.
  * **Mitigation:** Utilize well-tested Python libraries (e.g., `requests`). Implement thorough logging within DAGs. Start with core metrics and iterate. Ensure DAGs are idempotent.
* **Risk:** Streamlit dashboard performance degradation with a large number of projects or very long date ranges.
  * **Mitigation:** Optimize PostgreSQL queries. Utilize Streamlit's caching mechanisms (`@st.cache_data`, `@st.cache_resource`). Consider data aggregation in ETL for overview dashboards if direct queries become too slow (though raw data table is a requirement).
* **Risk:** Initial historical data load taking excessive time or causing high load on SonarQube.
  * **Mitigation:** Design ETL to process historical data in manageable chunks (e.g., month by month). Allow configuration of the historical depth. Implement appropriate delays between API calls if necessary.
* **Risk:** PostgreSQL schema may need to evolve if new metrics or deeper analysis dimensions are required.
  * **Mitigation:** Design an initial schema that is somewhat flexible. Document the schema well. Use Airflow or a separate migration tool for schema changes if complex evolution is needed post-deployment.
* **Risk:** Increased overall resource consumption on the developer's machine due to additional containers.
  * **Mitigation:** Provide estimates of resource requirements. Use official lightweight base images where possible. Document how users can adjust Docker resource allocations.
* **Risk:** SonarQube API changes in future versions could break ETL.
  * **Mitigation:** Pin SonarQube version in the base BRD or clearly document the version the ETL is compatible with. Implement version checking or flexible API call patterns if possible.

**15. Success Criteria:**

* The Streamlit, Airflow, and PostgreSQL services can be successfully launched via the updated `docker-compose up` command.
* The Airflow ETL DAG runs successfully on its nightly schedule, extracting data from SonarQube and populating/updating the PostgreSQL database.
* The Streamlit dashboard accurately displays:
  * KPI cards with correct values and trend indicators.
  * Trend graphs reflecting historical data from the PostgreSQL database.
  * Project comparison charts based on selected metrics.
  * A data table with correct, filterable data.
* All defined filters (Category, Date Range, Metric-Specific) function correctly and update the dashboard visualizations and data table.
* Data displayed in the dashboard is consistent with the data in SonarQube (considering ETL processing and scheduling).
* The CSV export function from the data table works correctly.
* Historical data for the last 3 months is successfully loaded during the initial ETL run.
* Documentation for accessing and understanding the dashboard and high-level ETL/DB components is clear and sufficient.

**16. Future Considerations (Optional):**

* Adding more advanced or custom visualizations to the Streamlit dashboard.
* Implementing user authentication and role-based access for the dashboard.
* Integrating alerts (e.g., email, Slack) for ETL failures or when certain metric thresholds are breached.
* Allowing filtering by SonarQube project tags.
* Expanding metric-specific filters (e.g., by SonarQube rule for Code Smells if a manageable list can be derived).
* Providing an option to configure the list of projects to monitor directly in Airflow/Dashboard UI instead of only "all projects."
* Adding ETL for SonarQube Quality Gate status and history.

---